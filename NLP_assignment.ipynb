{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment to implement pos tagging of given content stored in a Text Files and represent them in the form of n-grams!**"
      ],
      "metadata": {
        "id": "9s8DJzyXcDYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M4LMMVkbT3PL"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "from nltk import RegexpParser"
      ],
      "metadata": {
        "id": "MQxJ8qwLWp-w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pos tagging\n",
        "text = \"Today is NLP Presentation in the third hour\".split()\n",
        "print(\"after split:\", text)\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "tokens = pos_tag(text)\n",
        "print(\"after tokens:\", tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp8bkLfVWqEO",
        "outputId": "726a191d-236e-45c4-f19e-85b2b58ab668"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after split: ['Today', 'is', 'NLP', 'Presentation', 'in', 'the', 'third', 'hour']\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "after tokens: [('Today', 'NN'), ('is', 'VBZ'), ('NLP', 'NNP'), ('Presentation', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('third', 'JJ'), ('hour', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chunking\n",
        "patterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
        "chunker = RegexpParser(patterns)\n",
        "print(\"after chunk:\", chunker)\n",
        "output = chunker.parse(tokens)\n",
        "print(\"After Chunking\",output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mbsx5LfYXbq",
        "outputId": "9ae2475d-1cb0-4439-d932-6ff017503b90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after chunk: chunk.RegexpParser with 1 stages:\n",
            "RegexpChunkParser with 1 rules:\n",
            "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC>?'>\n",
            "After Chunking (S\n",
            "  (mychunk Today/NN)\n",
            "  is/VBZ\n",
            "  (mychunk NLP/NNP Presentation/NNP)\n",
            "  in/IN\n",
            "  the/DT\n",
            "  (mychunk third/JJ)\n",
            "  (mychunk hour/NN))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputfile = open(\"/content/textfile.txt\").read()\n",
        "type(inputfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uF7MQlstqjS",
        "outputId": "6f4196b0-3e99-4b6c-9e9e-5aca0da6788a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import RegexpParser\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "text = inputfile\n",
        "print(sent_tokenize(text))"
      ],
      "metadata": {
        "id": "yQ0Zie09t0m1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546a637f-aa28-4ccb-f6bc-85a0dcecde26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['This classic fable (story) tells the story of a very slow tortoise (another word for turtle) \\nand a speedy hare (another word for rabbit).', 'The tortoise challenges the hare to a race.', 'The hare laughs at the idea that a tortoise could run faster than him, \\nbut when the two actually race, the results are surprising.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization and POS Tagging \n",
        "from nltk.tokenize import word_tokenize\n",
        "text = inputfile\n",
        "print(\"This tokenization prints all words including punctuations!\")\n",
        "print(\"-------------------------\")\n",
        "\n",
        "words_tokens = word_tokenize(text)\n",
        "print(words_tokens)\n",
        "\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "\n",
        "nltk.pos_tag(words_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmPqR8nsuHKD",
        "outputId": "0dc01e44-6c57-4837-8cee-53afb12d2d54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This tokenization prints all words including punctuations!\n",
            "-------------------------\n",
            "['This', 'classic', 'fable', '(', 'story', ')', 'tells', 'the', 'story', 'of', 'a', 'very', 'slow', 'tortoise', '(', 'another', 'word', 'for', 'turtle', ')', 'and', 'a', 'speedy', 'hare', '(', 'another', 'word', 'for', 'rabbit', ')', '.', 'The', 'tortoise', 'challenges', 'the', 'hare', 'to', 'a', 'race', '.', 'The', 'hare', 'laughs', 'at', 'the', 'idea', 'that', 'a', 'tortoise', 'could', 'run', 'faster', 'than', 'him', ',', 'but', 'when', 'the', 'two', 'actually', 'race', ',', 'the', 'results', 'are', 'surprising', '.']\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('classic', 'JJ'),\n",
              " ('fable', 'JJ'),\n",
              " ('(', '('),\n",
              " ('story', 'NN'),\n",
              " (')', ')'),\n",
              " ('tells', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('story', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('very', 'RB'),\n",
              " ('slow', 'JJ'),\n",
              " ('tortoise', 'NN'),\n",
              " ('(', '('),\n",
              " ('another', 'DT'),\n",
              " ('word', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('turtle', 'NN'),\n",
              " (')', ')'),\n",
              " ('and', 'CC'),\n",
              " ('a', 'DT'),\n",
              " ('speedy', 'NN'),\n",
              " ('hare', 'NN'),\n",
              " ('(', '('),\n",
              " ('another', 'DT'),\n",
              " ('word', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('rabbit', 'NN'),\n",
              " (')', ')'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('tortoise', 'NN'),\n",
              " ('challenges', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('hare', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('a', 'DT'),\n",
              " ('race', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'DT'),\n",
              " ('hare', 'NN'),\n",
              " ('laughs', 'VBZ'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('idea', 'NN'),\n",
              " ('that', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('tortoise', 'NN'),\n",
              " ('could', 'MD'),\n",
              " ('run', 'VB'),\n",
              " ('faster', 'JJR'),\n",
              " ('than', 'IN'),\n",
              " ('him', 'PRP'),\n",
              " (',', ','),\n",
              " ('but', 'CC'),\n",
              " ('when', 'WRB'),\n",
              " ('the', 'DT'),\n",
              " ('two', 'CD'),\n",
              " ('actually', 'RB'),\n",
              " ('race', 'NN'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('results', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('surprising', 'JJ'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Chunking process\n",
        "text = inputfile\n",
        "grammar = ('''\n",
        "    NP: {<DT>?<JJ>*<NN>} # NP\n",
        "    ''')\n",
        "chunkparser = nltk.RegexpParser(grammar)\n",
        "print(chunkparser)\n",
        "tagged = chunkparser.parse(nltk.pos_tag(text.split(' ')))\n",
        "print(tagged)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsBWzSYFufyl",
        "outputId": "7b016094-2e6d-4335-c7ba-3d9f3e47a465"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chunk.RegexpParser with 1 stages:\n",
            "RegexpChunkParser with 1 rules:\n",
            "    NP   <ChunkRule: '<DT>?<JJ>*<NN>'>\n",
            "(S\n",
            "  (NP This/DT classic/JJ fable/JJ (story)/NN)\n",
            "  tells/VBZ\n",
            "  (NP the/DT story/NN)\n",
            "  of/IN\n",
            "  a/DT\n",
            "  very/RB\n",
            "  (NP slow/JJ tortoise/NN)\n",
            "  (NP (another/NN)\n",
            "  (NP word/NN)\n",
            "  for/IN\n",
            "  (NP turtle)/NN)\n",
            "  \n",
            "and/VBP\n",
            "  (NP a/DT speedy/NN)\n",
            "  (NP hare/NN)\n",
            "  (another/NNP\n",
            "  (NP word/NN)\n",
            "  for/IN\n",
            "  (NP rabbit)./NN)\n",
            "  (NP The/DT tortoise/NN)\n",
            "  challenges/VBZ\n",
            "  (NP the/DT hare/NN)\n",
            "  to/TO\n",
            "  (NP a/DT race./NN)\n",
            "  \n",
            "The/NNP\n",
            "  (NP hare/NN)\n",
            "  laughs/VBZ\n",
            "  at/IN\n",
            "  (NP the/DT idea/NN)\n",
            "  that/IN\n",
            "  (NP a/DT tortoise/NN)\n",
            "  could/MD\n",
            "  run/VB\n",
            "  faster/JJR\n",
            "  than/IN\n",
            "  him,/NNS\n",
            "  \n",
            "but/VBP\n",
            "  when/WRB\n",
            "  the/DT\n",
            "  two/CD\n",
            "  actually/RB\n",
            "  race,/VBP\n",
            "  the/DT\n",
            "  results/NNS\n",
            "  are/VBP\n",
            "  surprising./JJ)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "bigram = list(ngrams(text.split(),2))\n",
        "trigram = list(ngrams(text.split(),3))\n",
        "print(bigram)\n",
        "print(trigram)"
      ],
      "metadata": {
        "id": "yVWt7MAr0bIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fbf8c9-8dc8-44d5-a15a-8e8997ee1570"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('This', 'classic'), ('classic', 'fable'), ('fable', '(story)'), ('(story)', 'tells'), ('tells', 'the'), ('the', 'story'), ('story', 'of'), ('of', 'a'), ('a', 'very'), ('very', 'slow'), ('slow', 'tortoise'), ('tortoise', '(another'), ('(another', 'word'), ('word', 'for'), ('for', 'turtle)'), ('turtle)', 'and'), ('and', 'a'), ('a', 'speedy'), ('speedy', 'hare'), ('hare', '(another'), ('(another', 'word'), ('word', 'for'), ('for', 'rabbit).'), ('rabbit).', 'The'), ('The', 'tortoise'), ('tortoise', 'challenges'), ('challenges', 'the'), ('the', 'hare'), ('hare', 'to'), ('to', 'a'), ('a', 'race.'), ('race.', 'The'), ('The', 'hare'), ('hare', 'laughs'), ('laughs', 'at'), ('at', 'the'), ('the', 'idea'), ('idea', 'that'), ('that', 'a'), ('a', 'tortoise'), ('tortoise', 'could'), ('could', 'run'), ('run', 'faster'), ('faster', 'than'), ('than', 'him,'), ('him,', 'but'), ('but', 'when'), ('when', 'the'), ('the', 'two'), ('two', 'actually'), ('actually', 'race,'), ('race,', 'the'), ('the', 'results'), ('results', 'are'), ('are', 'surprising.')]\n",
            "[('This', 'classic', 'fable'), ('classic', 'fable', '(story)'), ('fable', '(story)', 'tells'), ('(story)', 'tells', 'the'), ('tells', 'the', 'story'), ('the', 'story', 'of'), ('story', 'of', 'a'), ('of', 'a', 'very'), ('a', 'very', 'slow'), ('very', 'slow', 'tortoise'), ('slow', 'tortoise', '(another'), ('tortoise', '(another', 'word'), ('(another', 'word', 'for'), ('word', 'for', 'turtle)'), ('for', 'turtle)', 'and'), ('turtle)', 'and', 'a'), ('and', 'a', 'speedy'), ('a', 'speedy', 'hare'), ('speedy', 'hare', '(another'), ('hare', '(another', 'word'), ('(another', 'word', 'for'), ('word', 'for', 'rabbit).'), ('for', 'rabbit).', 'The'), ('rabbit).', 'The', 'tortoise'), ('The', 'tortoise', 'challenges'), ('tortoise', 'challenges', 'the'), ('challenges', 'the', 'hare'), ('the', 'hare', 'to'), ('hare', 'to', 'a'), ('to', 'a', 'race.'), ('a', 'race.', 'The'), ('race.', 'The', 'hare'), ('The', 'hare', 'laughs'), ('hare', 'laughs', 'at'), ('laughs', 'at', 'the'), ('at', 'the', 'idea'), ('the', 'idea', 'that'), ('idea', 'that', 'a'), ('that', 'a', 'tortoise'), ('a', 'tortoise', 'could'), ('tortoise', 'could', 'run'), ('could', 'run', 'faster'), ('run', 'faster', 'than'), ('faster', 'than', 'him,'), ('than', 'him,', 'but'), ('him,', 'but', 'when'), ('but', 'when', 'the'), ('when', 'the', 'two'), ('the', 'two', 'actually'), ('two', 'actually', 'race,'), ('actually', 'race,', 'the'), ('race,', 'the', 'results'), ('the', 'results', 'are'), ('results', 'are', 'surprising.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TqMlGIQ78G0G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}